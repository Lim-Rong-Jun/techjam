{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from opendatasets) (4.67.1)\n",
      "Collecting kaggle (from opendatasets)\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting click (from opendatasets)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Collecting bleach (from kaggle->opendatasets)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (3.4.3)\n",
      "Requirement already satisfied: idna in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (6.32.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle->opendatasets)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle->opendatasets)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\thund\\desktop\\individual_project\\.venv\\lib\\site-packages (from kaggle->opendatasets) (2.5.0)\n",
      "Collecting webencodings (from kaggle->opendatasets)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, python-slugify, click, bleach, kaggle, opendatasets\n",
      "\n",
      "   ----------- ---------------------------- 2/7 [python-slugify]\n",
      "   ----------------- ---------------------- 3/7 [click]\n",
      "   ---------------------- ----------------- 4/7 [bleach]\n",
      "   ---------------------- ----------------- 4/7 [bleach]\n",
      "   ---------------------- ----------------- 4/7 [bleach]\n",
      "   ---------------------- ----------------- 4/7 [bleach]\n",
      "   ---------------------------- ----------- 5/7 [kaggle]\n",
      "   ---------------------------- ----------- 5/7 [kaggle]\n",
      "   ---------------------------- ----------- 5/7 [kaggle]\n",
      "   ---------------------------- ----------- 5/7 [kaggle]\n",
      "   ---------------------------- ----------- 5/7 [kaggle]\n",
      "   ---------------------------------- ----- 6/7 [opendatasets]\n",
      "   ---------------------------------------- 7/7 [opendatasets]\n",
      "\n",
      "Successfully installed bleach-6.2.0 click-8.2.1 kaggle-1.7.4.5 opendatasets-0.1.22 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n",
    "# !pip install numpy\n",
    "# !pip install transformers datasets accelerate evaluate sentencepiece protobuf huggingface_hub\n",
    "# !pip install opendatasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thund\\Desktop\\individual_project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Core Transformers (models + tokenizers + pipelines)\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Hugging Face Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Training accelerator (multi-GPU, TPU, CPU support)\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Evaluation metrics\n",
    "import evaluate\n",
    "\n",
    "# SentencePiece (used behind the scenes, rarely imported directly)\n",
    "# import sentencepiece  # usually not needed directly, required internally\n",
    "\n",
    "# Hugging Face Hub (upload/download models & datasets)\n",
    "from huggingface_hub import HfApi, notebook_login\n",
    "\n",
    "import opendatasets as od\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opendatasets.datasets.C:/Users/thund/Downloads/archive/reviews'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:/Users/thund/Downloads/archive/reviews.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thund\\Desktop\\individual_project\\.venv\\Lib\\site-packages\\opendatasets\\__init__.py:27\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(data_dir):\n\u001b[32m     26\u001b[39m     os.makedirs(data_dir)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m dataset = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopendatasets.datasets.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dry_run:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mThis is a dry run. URLs will be displayed but the files will not be downloaded.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1310\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'opendatasets.datasets.C:/Users/thund/Downloads/archive/reviews'"
     ]
    }
   ],
   "source": [
    "# od.download(\"C:/Users/thund/Downloads/archive/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(\"C:/Users/thund/Desktop/Github/techjam/dataset/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "business_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "photo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rating_category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d7cebcd0-c523-4b77-a49d-07a5c9c99c32",
       "rows": [
        [
         "0",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Gulsum Akar",
         "We went to Marmaris with my wife for a holiday. We chose this restaurant as a place for dinner based on the reviews and because we wanted juicy food. When we first went there was a serious queue. You proceed by taking the food you want in the form of an open buffet. Both vegetable dishes and meat dishes were plentiful. There was also dessert for those who wanted it. After you get what you want you pay at the cashier. They don't go through cards they work in cash. There was a lot of food variety. And the food prices were unbelievably cheap. We paid only 84 TL for all the meals here. It included buttermilk and bread. But unfortunately I can't say it's too clean as a place..",
         "dataset/taste/hacinin_yeri_gulsum_akar.png",
         "5",
         "taste"
        ],
        [
         "1",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Oguzhan Cetin",
         "During my holiday in Marmaris we ate here to fit the food. It's really good that the food is cheap and nice. Eating as much bread as you want is a big plus for those who are not satisfied without bread. It is a place that I can recommend to those who will go to Marmaris. On July 1 there was a small increase but even the price hike is cheap. I leave the photo of the latest prices and breakfast below. there was a serious queue. You proceed by taking the food you want in the form of an open buffet. Both vegetable dishes and meat dishes were plentiful. There was also dessert for those who wanted it. After you get what you want you pay at the cashier. They don't go through cards they work in cash. There was a lot of food variety. And the food prices were unbelievably cheap. We paid only 84 TL for all the meals here. It included buttermilk and bread. But unfortunately I can't say it's too clean as a place..",
         "dataset/menu/hacinin_yeri_oguzhan_cetin.png",
         "4",
         "menu"
        ],
        [
         "2",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Yasin Kuyu",
         "Prices are very affordable. The menu in the photo cost 108 liras. You have to wait 10-15 minutes for food. Staff is annoying. Well it tastes good. Boiled meat was delicious.",
         "dataset/outdoor_atmosphere/hacinin_yeri_yasin_kuyu.png",
         "3",
         "outdoor_atmosphere"
        ],
        [
         "3",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Orhan Kapu",
         "Turkey's cheapest artisan restaurant and its food is delicious!",
         "dataset/indoor_atmosphere/hacinin_yeri_orhan_kapu.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "4",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Ozgur Sati",
         "I don't know what you will look for in terms of price performance point; taste; but yigit restaurant writes a big plus for those who come to work in this region.",
         "dataset/menu/hacinin_yeri_ozgur_sati.png",
         "3",
         "menu"
        ],
        [
         "5",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Arda Karaca",
         "Generally good.",
         "dataset/indoor_atmosphere/hacinin_yeri_arda_karaca.png",
         "4",
         "indoor_atmosphere"
        ],
        [
         "6",
         "Haci'nin Yeri - Yigit Lokantasi",
         "İrem Eren",
         "What you see is 125 TL in total. It's a pretty convenient place. We can say that it is an artisan restaurant; you should not expect a restaurant; but they are still quite good in terms of price and performance. As of July 1; prices will increase",
         "dataset/taste/hacinin_yeri_irem_eren.png",
         "5",
         "taste"
        ],
        [
         "7",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Nadia Salim",
         "Delicious food at rock bottom prices. Friendly staff; Highly recommend",
         "dataset/taste/hacinin_yeri_nadia_salim.png",
         "5",
         "taste"
        ],
        [
         "8",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Mehmet Eser",
         "Every time I go, I still experience the amazement I experienced years ago as if it were the first time. There is no need to explain. Folk hero is a business.",
         "dataset/outdoor_atmosphere/hacinin_yeri_mehmet_eser.png",
         "5",
         "outdoor_atmosphere"
        ],
        [
         "9",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Celal Ozer",
         "The most f/p of all businesses I've seen.",
         "dataset/indoor_atmosphere/hacinin_yeri_celal_ozer.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "10",
         "Haci'nin Yeri - Yigit Lokantasi",
         "Onur Celebi",
         "The food was just like the ones my mother made. Prices were reasonable.",
         "dataset/taste/hacinin_yeri_onur_celebi.png",
         "5",
         "taste"
        ],
        [
         "11",
         "Pizza Fellas",
         "Kadir Tasci",
         "The ambiance of the place is nice; when we went; there was a lot of queue; and after waiting for a while; they took our place. The friend who took our order said half a half pizza and we preferred half chicken and half steak. Two people were easily satisfied; a lot of patterns.",
         "dataset/indoor_atmosphere/pizza_fellas_kadir_tasci.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "12",
         "Pizza Fellas",
         "Serkan Colak",
         "Flavor : It has nothing but dough taste. Labor : Not befitting a touristic place. Service : There was no wet wipes and napkins on the table, but there was no sympathetic family to say. This service and this taste were not available at this price.",
         "dataset/taste/pizza_fellas_serkan_colak.png",
         "2",
         "taste"
        ],
        [
         "13",
         "Pizza Fellas",
         "Selim Cun",
         "It is in the center; easy to reach; close to the parking lot; the prices are partially affordable; the products are delicious but not quite satisfying; the seating places are cramped; the place is a little flat.",
         "dataset/indoor_atmosphere/pizza_fellas_selim_cun.png",
         "4",
         "indoor_atmosphere"
        ],
        [
         "14",
         "Pizza Fellas",
         "Zeki Celik",
         "They make delicious pizza with nice ingredients on thin dough. Slice pizza and all pizza options are available. You can try two different flavors as a whole by making two different choices for the whole pizza. We wanted the mushroom and sausage. It was very nice; warm; and it was cooked in its consistency without drying the ingredients.",
         "dataset/outdoor_atmosphere/pizza_fellas_zeki_celik.png",
         "5",
         "outdoor_atmosphere"
        ],
        [
         "15",
         "Pizza Fellas",
         "Mustafa Caliskan",
         "It's in a nice place but it's very small and their pizza is not that good to be exaggerated. Pizza dough is nice and thin. They do not offer advice to the customer.",
         "dataset/taste/pizza_fellas_mustafa_caliskan.png",
         "3",
         "taste"
        ],
        [
         "16",
         "Pizza Fellas",
         "Deniz Bilgin",
         "I strongly recommend. If I come to the taste part; it was very enjoyable to eat with their special sauces. Also the whole pizza was huge.",
         "dataset/outdoor_atmosphere/pizza_fellas_deniz_bilgin.png",
         "5",
         "outdoor_atmosphere"
        ],
        [
         "17",
         "Pizza Fellas",
         "Cihan Tas",
         "It is very tasty; similar to Italian pizzas. Roast beef and mohair 180 TL; other pizzas 150 TL. An adult male eats 6 slices; pizzas are one size and 8 slices.",
         "dataset/menu/pizza_fellas_cihan_tas.png",
         "4",
         "menu"
        ],
        [
         "18",
         "Pizza Fellas",
         "Seda Sinem",
         "Do not come around Marmaris and do not leave without eating pizza at Pizza Fellas. We ate mixed pizza; they can make two types of pizza. So delicious!",
         "dataset/taste/pizza_fellas_seda_sinem.png",
         "5",
         "taste"
        ],
        [
         "19",
         "Pizza Fellas",
         "Nesrin Kuyumcu",
         "I never thought that the best pizza I've ever eaten would be in Akyaka. Thin pizzas are very tasty and the options are very good. We recommend it to everyone who comes to Akyaka.",
         "dataset/menu/pizza_fellas_nesrin_kuyumcu.png",
         "5",
         "menu"
        ],
        [
         "20",
         "Pizza Fellas",
         "Okan Uslu",
         "It was as if a very delicious Italian chef had come out of his hands. You can eat with pleasure. The owners are very good people. I recommend.",
         "dataset/indoor_atmosphere/pizza_fellas_okan_uslu.png",
         "4",
         "indoor_atmosphere"
        ],
        [
         "21",
         "Pizza Fellas",
         "Huseyin Uysal",
         "The pizza is big enough for 2 people. The dough is very thin. Price is between 120-140 TL.",
         "dataset/taste/pizza_fellas_huseyin_uysal.png",
         "4",
         "taste"
        ],
        [
         "22",
         "Cafe Inn",
         "Dila Kocatepe",
         "The environment; the interest and friendliness of the employees; the taste is incredible. It is so beautiful inside that you do not prefer to sit at the bottom of the sea. Depending on the day; there are also things that are not written on the menu; be sure to check it out. Hours have passed since the meal; we are still talking about the beef brisket.",
         "dataset/indoor_atmosphere/cafe_inn_dila_kocatepe.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "23",
         "Cafe Inn",
         "Hooman Sadati",
         "Without any taste how they are at the first rank!!!! We ate cafe Inn pizza. It was 70 tl.",
         "dataset/taste/cafe_inn_hooman_sadati.png",
         "1",
         "taste"
        ],
        [
         "24",
         "Cafe Inn",
         "Serap Gunay",
         "Pizza is delicious.. I can say it is one of the rare tastes. Prices are in the 200-300 range and one pizza is more than enough for two people if you are not very hungry. The scenery is already gorgeous.",
         "dataset/indoor_atmosphere/cafe_inn_serap_gunay.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "25",
         "Cafe Inn",
         "Tugba Gunaydin",
         "The vegan breakfast made me extremely happy. It was nice.",
         "dataset/menu/cafe_inn_tugba_gunaydin.png",
         "4",
         "menu"
        ],
        [
         "26",
         "Cafe Inn",
         "Can Ozdemir",
         "Whatever we ate was good. The Italian Restaurant is the first thing that comes to mind; apart from pizza and pasta; ciger yahni was successful; purslane salad; presentations are successful. Taste point in Datca.",
         "dataset/outdoor_atmosphere/cafe_inn_can_ozdemir.png",
         "5",
         "outdoor_atmosphere"
        ],
        [
         "27",
         "Cafe Inn",
         "Berk Basarir",
         "Very enjoyable beautiful place. Pizza salad food taste is great.",
         "dataset/taste/cafe_inn_berk_basarir.png",
         "5",
         "taste"
        ],
        [
         "28",
         "Cafe Inn",
         "Mert Ozer",
         "Its breakfast is more satisfying than the places around it.",
         "dataset/indoor_atmosphere/cafe_inn_mert_ozer.png",
         "4",
         "indoor_atmosphere"
        ],
        [
         "29",
         "Cafe Inn",
         "Kain Dijkman",
         "Nice intimate restaurant. Good service. Eye for detail. Clean. Really good food; well presented.",
         "dataset/outdoor_atmosphere/cafe_inn_kain_dijkman.png",
         "5",
         "outdoor_atmosphere"
        ],
        [
         "30",
         "Cafe Inn",
         "Sarp Kendirci",
         "The food is delicious but a little pricey. The best Cappucino in Datça is here..",
         "dataset/menu/cafe_inn_sarp_kendirci.png",
         "3",
         "menu"
        ],
        [
         "31",
         "Cafe Inn",
         "Zafer Togay",
         "It's a very delicious; beautiful small business; but the appointment is a bit difficult to find; the pizzas are great Cafe Inn pizza and a wonderful 4 cheese and brownie as dessert. Thank you for your good wishes.",
         "dataset/taste/cafe_inn_zafer_togay.png",
         "5",
         "taste"
        ],
        [
         "32",
         "Cafe Inn",
         "Eren Kesti",
         "When I went; I waited for almost 20 minutes for the waiters to take care of me. The taste was not bad. The surrounding was beautiful.",
         "dataset/outdoor_atmosphere/cafe_inn_eren_kesti.png",
         "2",
         "outdoor_atmosphere"
        ],
        [
         "33",
         "Riviera",
         "Olgayali Yilmaz",
         "It is a very, very expensive place. It took 30 minutes for 2 drinks to arrive.",
         "dataset/menu/riviera_olgayali_yilmaz.png",
         "3",
         "menu"
        ],
        [
         "34",
         "Riviera",
         "Gorkey Bardakci",
         "I had the creamy chicken vegetable stew. It tasted excellent. It was quite satisfying. The environment is beautiful and spacious.",
         "dataset/taste/riviera_gorkey_bardakci.png",
         "5",
         "taste"
        ],
        [
         "35",
         "Riviera",
         "Mehmet Yaliniz",
         "quality service and rich menu. the attitude of the staff is really excellent. A business that deserves 5 stars.",
         "dataset/outdoor_atmosphere/riviera_mehmet_yaliniz.png",
         "5",
         "outdoor_atmosphere"
        ],
        [
         "36",
         "Riviera",
         "Goksel Aybek",
         "The sushi was too small so it was not possible to taste the ingredients; the rice was overcooked and lacked flavor; it was missing except for the tail of the shrimp.",
         "dataset/taste/riviera_goksel_aybek.png",
         "2",
         "taste"
        ],
        [
         "37",
         "Riviera",
         "Cahide Koral",
         "The staff was very engaged. Service and taste were perfect.",
         "dataset/indoor_atmosphere/riviera_cahide_koral.png",
         "4",
         "indoor_atmosphere"
        ],
        [
         "38",
         "Riviera",
         "Aya Zhol",
         "Perfect location next to the sea. Music; light in the evening lounge atmosphere. In short; everything is beautiful.",
         "dataset/outdoor_atmosphere/riviera_aya_zhol.png",
         "4",
         "outdoor_atmosphere"
        ],
        [
         "39",
         "Riviera",
         "Metin Tumay",
         "It was very expensive, but taste wasn't bad.",
         "dataset/menu/riviera_metin_tumay.png",
         "2",
         "menu"
        ],
        [
         "40",
         "Riviera",
         "Yılmaz Unal",
         "Good quality service; nice customer service; they are happy to help with a smile.",
         "dataset/indoor_atmosphere/riviera_yılmaz_unal.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "41",
         "Riviera",
         "Alex Aali",
         "Scrambled eggs with casserole and toast waited 30 minutes. At 12:30pm the main menu was denied and showed only breakfast available. Prices are much higher than other places.",
         "dataset/taste/riviera_alex_aali.png",
         "2",
         "taste"
        ],
        [
         "42",
         "Riviera",
         "Yahya Nawar",
         "Nice view, good staff, clean place and nice atmosphere.",
         "dataset/outdoor_atmosphere/riviera_yahya_nawar.png",
         "3",
         "outdoor_atmosphere"
        ],
        [
         "43",
         "Riviera",
         "Nirmal Narayan",
         "Nice food and good service; located just near the beach as well.",
         "dataset/indoor_atmosphere/riviera_nirmal_narayan.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "44",
         "Sakip Usta Gaziantep",
         "Gamze Aciogli",
         "It was very nice to be greeted with a smile when we first entered; we went with my wife; the services are very fast; the empty services are removed immediately; the washbasins were hygienic and clean; and I would recommend a very reasonable place.",
         "dataset/taste/sakip_usta_gaziantep_gamze_aciogli.png",
         "4",
         "taste"
        ],
        [
         "45",
         "Sakip Usta Gaziantep",
         "Murat Erdemir",
         "Kebabs are good; trotters are good; desserts are good. Actually; the decor part of the atmosphere is good. Only a lot of noise comes from the kitchen part. Employees are smiling.",
         "dataset/outdoor_atmosphere/sakip_usta_gaziantep_murat_erdemir.png",
         "4",
         "outdoor_atmosphere"
        ],
        [
         "46",
         "Sakip Usta Gaziantep",
         "Berat Türk",
         "If you come to Antep; sit down and taste the Beyran soup; served plain and with garlic.",
         "dataset/indoor_atmosphere/sakip_usta_gaziantep_berat_turk.png",
         "5",
         "indoor_atmosphere"
        ],
        [
         "47",
         "Sakip Usta Gaziantep",
         "Agah Beyoglu",
         "I asked for garlic; but I had a hard time getting the taste of the meat from the garlic flavor. I'll try again with little or no garlic. Quite satisfying. I like the taste too; you should definitely try it.",
         "dataset/taste/sakip_usta_gaziantep_agah_beyoglu.png",
         "4",
         "taste"
        ],
        [
         "48",
         "Sakip Usta Gaziantep",
         "Serap Keskin",
         "Taste was amazing! Price was not high.",
         "dataset/menu/sakip_usta_gaziantep_serap_keskin.png",
         "4",
         "menu"
        ],
        [
         "49",
         "Sakip Usta Gaziantep",
         "Ahmet Coban",
         "When I ate it in the past; it tasted very good; I think the chef has changed. The atmosphere was average.",
         "dataset/indoor_atmosphere/sakip_usta_gaziantep_ahmet_coban.png",
         "2",
         "indoor_atmosphere"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>author_name</th>\n",
       "      <th>text</th>\n",
       "      <th>photo</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Gulsum Akar</td>\n",
       "      <td>We went to Marmaris with my wife for a holiday...</td>\n",
       "      <td>dataset/taste/hacinin_yeri_gulsum_akar.png</td>\n",
       "      <td>5</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Oguzhan Cetin</td>\n",
       "      <td>During my holiday in Marmaris we ate here to f...</td>\n",
       "      <td>dataset/menu/hacinin_yeri_oguzhan_cetin.png</td>\n",
       "      <td>4</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Yasin Kuyu</td>\n",
       "      <td>Prices are very affordable. The menu in the ph...</td>\n",
       "      <td>dataset/outdoor_atmosphere/hacinin_yeri_yasin_...</td>\n",
       "      <td>3</td>\n",
       "      <td>outdoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Orhan Kapu</td>\n",
       "      <td>Turkey's cheapest artisan restaurant and its f...</td>\n",
       "      <td>dataset/indoor_atmosphere/hacinin_yeri_orhan_k...</td>\n",
       "      <td>5</td>\n",
       "      <td>indoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Ozgur Sati</td>\n",
       "      <td>I don't know what you will look for in terms o...</td>\n",
       "      <td>dataset/menu/hacinin_yeri_ozgur_sati.png</td>\n",
       "      <td>3</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Miss Pizza</td>\n",
       "      <td>Salih Gursoy</td>\n",
       "      <td>There are so many types of pizza; you are surp...</td>\n",
       "      <td>dataset/taste/miss_pizza_salih_gursoy.png</td>\n",
       "      <td>5</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>Miss Pizza</td>\n",
       "      <td>Kemal Amangeldi</td>\n",
       "      <td>I tried the smoked ribeye pizza; the dough is ...</td>\n",
       "      <td>dataset/indoor_atmosphere/miss_pizza_kemal_ama...</td>\n",
       "      <td>5</td>\n",
       "      <td>indoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>Miss Pizza</td>\n",
       "      <td>Ulkem Esen</td>\n",
       "      <td>Crowded and expensive place.</td>\n",
       "      <td>dataset/menu/miss_pizza_ulkem_esen.png</td>\n",
       "      <td>3</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>Miss Pizza</td>\n",
       "      <td>Ilkin Saymaz</td>\n",
       "      <td>No bad. It was very crowded; there was no ligh...</td>\n",
       "      <td>dataset/taste/miss_pizza_ilkin_saymaz.png</td>\n",
       "      <td>3</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>Miss Pizza</td>\n",
       "      <td>Samet Selcuk</td>\n",
       "      <td>Excellent pizza and fine wine. Both food and b...</td>\n",
       "      <td>dataset/outdoor_atmosphere/miss_pizza_samet_se...</td>\n",
       "      <td>4</td>\n",
       "      <td>outdoor_atmosphere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        business_name      author_name  \\\n",
       "0     Haci'nin Yeri - Yigit Lokantasi      Gulsum Akar   \n",
       "1     Haci'nin Yeri - Yigit Lokantasi    Oguzhan Cetin   \n",
       "2     Haci'nin Yeri - Yigit Lokantasi       Yasin Kuyu   \n",
       "3     Haci'nin Yeri - Yigit Lokantasi       Orhan Kapu   \n",
       "4     Haci'nin Yeri - Yigit Lokantasi       Ozgur Sati   \n",
       "...                               ...              ...   \n",
       "1095                       Miss Pizza     Salih Gursoy   \n",
       "1096                       Miss Pizza  Kemal Amangeldi   \n",
       "1097                       Miss Pizza       Ulkem Esen   \n",
       "1098                       Miss Pizza     Ilkin Saymaz   \n",
       "1099                       Miss Pizza     Samet Selcuk   \n",
       "\n",
       "                                                   text  \\\n",
       "0     We went to Marmaris with my wife for a holiday...   \n",
       "1     During my holiday in Marmaris we ate here to f...   \n",
       "2     Prices are very affordable. The menu in the ph...   \n",
       "3     Turkey's cheapest artisan restaurant and its f...   \n",
       "4     I don't know what you will look for in terms o...   \n",
       "...                                                 ...   \n",
       "1095  There are so many types of pizza; you are surp...   \n",
       "1096  I tried the smoked ribeye pizza; the dough is ...   \n",
       "1097                       Crowded and expensive place.   \n",
       "1098  No bad. It was very crowded; there was no ligh...   \n",
       "1099  Excellent pizza and fine wine. Both food and b...   \n",
       "\n",
       "                                                  photo  rating  \\\n",
       "0            dataset/taste/hacinin_yeri_gulsum_akar.png       5   \n",
       "1           dataset/menu/hacinin_yeri_oguzhan_cetin.png       4   \n",
       "2     dataset/outdoor_atmosphere/hacinin_yeri_yasin_...       3   \n",
       "3     dataset/indoor_atmosphere/hacinin_yeri_orhan_k...       5   \n",
       "4              dataset/menu/hacinin_yeri_ozgur_sati.png       3   \n",
       "...                                                 ...     ...   \n",
       "1095          dataset/taste/miss_pizza_salih_gursoy.png       5   \n",
       "1096  dataset/indoor_atmosphere/miss_pizza_kemal_ama...       5   \n",
       "1097             dataset/menu/miss_pizza_ulkem_esen.png       3   \n",
       "1098          dataset/taste/miss_pizza_ilkin_saymaz.png       3   \n",
       "1099  dataset/outdoor_atmosphere/miss_pizza_samet_se...       4   \n",
       "\n",
       "         rating_category  \n",
       "0                  taste  \n",
       "1                   menu  \n",
       "2     outdoor_atmosphere  \n",
       "3      indoor_atmosphere  \n",
       "4                   menu  \n",
       "...                  ...  \n",
       "1095               taste  \n",
       "1096   indoor_atmosphere  \n",
       "1097                menu  \n",
       "1098               taste  \n",
       "1099  outdoor_atmosphere  \n",
       "\n",
       "[1100 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pseudo labelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def rule_based_label(review):\n",
    "#     if re.search(r\"http|www|discount|promo\", review.lower()):\n",
    "#         return \"Advertisement\"\n",
    "#     if any(word in review.lower() for word in [\"phone\", \"car\", \"delivery\"]):\n",
    "#         return \"Irrelevant\"\n",
    "#     if \"never been here\" in review.lower() or \"heard it's bad\" in review.lower():\n",
    "#         return \"Rant_no_visit\"\n",
    "#     return \"Trustworthy\"\n",
    "\n",
    "# df[\"label\"] = df[\"review\"].apply(rule_based_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 106.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': 'Great food!', 'label': 1, 'input_ids': [101, 2307, 2833, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Example DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"review\": [\"Great food!\", \"Terrible service.\"], \"label\": [1, 0]})\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Batched tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 880/880 [00:00<00:00, 6570.74 examples/s]\n",
      "Map: 100%|██████████| 220/220 [00:00<00:00, 6412.06 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading builder script: 4.20kB [00:00, 4.20MB/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     80\u001b[39m     preds = np.argmax(logits, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy.compute(predictions=preds, references=labels)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./logs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     94\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m trainer = Trainer(\n\u001b[32m     97\u001b[39m     model=model,\n\u001b[32m     98\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m    103\u001b[39m )\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# 9. Train\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 1. Install dependencies (if not already done)\n",
    "# ===============================\n",
    "# !pip install transformers datasets accelerate evaluate sentencepiece protobuf huggingface_hub scikit-learn pandas numpy matplotlib seaborn\n",
    "\n",
    "# ===============================\n",
    "# 2. Imports\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "# 3. Load dataset (example: Google Maps reviews)\n",
    "# ===============================\n",
    "# Replace this with your Kaggle/CSV file path\n",
    "df = pd.read_csv(\"C:/Users/thund/Desktop/Github/techjam/dataset/reviews.csv\")\n",
    "\n",
    "# For demo, keep only review text\n",
    "df = df.rename(columns={\"text\": \"review\"})  # make sure column is named \"review\"\n",
    "\n",
    "# ===============================\n",
    "# 4. Pseudo-labeling (weak supervision)\n",
    "# ===============================\n",
    "import re\n",
    "\n",
    "def rule_based_label(review):\n",
    "    text = review.lower()\n",
    "    if re.search(r\"http|www|discount|promo\", text):\n",
    "        return 0  # Advertisement\n",
    "    if any(word in text for word in [\"phone\", \"car\", \"delivery\"]):\n",
    "        return 1  # Irrelevant\n",
    "    if \"never been here\" in text or \"heard it's bad\" in text:\n",
    "        return 2  # Rant_no_visit\n",
    "    return 3  # Trustworthy\n",
    "\n",
    "df[\"label\"] = df[\"review\"].astype(str).apply(rule_based_label)\n",
    "\n",
    "label_names = [\"Advertisement\", \"Irrelevant\", \"Rant_no_visit\", \"Trustworthy\"]\n",
    "\n",
    "# ===============================\n",
    "# 5. Convert to Hugging Face Dataset\n",
    "# ===============================\n",
    "dataset = Dataset.from_pandas(df[[\"review\", \"label\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# ===============================\n",
    "# 6. Tokenization\n",
    "# ===============================\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# ===============================\n",
    "# 7. Load Model\n",
    "# ===============================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_names)\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 8. Training setup\n",
    "# ===============================\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 9. Train\n",
    "# ===============================\n",
    "trainer.train()\n",
    "\n",
    "# ===============================\n",
    "# 10. Evaluate\n",
    "# ===============================\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation:\", results)\n",
    "\n",
    "# ===============================\n",
    "# 11. Save Model\n",
    "# ===============================\n",
    "trainer.save_model(\"./trustworthiness_model\")\n",
    "tokenizer.save_pretrained(\"./trustworthiness_model\")\n",
    "\n",
    "# ===============================\n",
    "# 12. Run Inference\n",
    "# ===============================\n",
    "inference_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"./trustworthiness_model\",\n",
    "    tokenizer=\"./trustworthiness_model\",\n",
    "    return_all_scores=False\n",
    ")\n",
    "\n",
    "test_texts = [\n",
    "    \"Never been here but I heard it's bad\",\n",
    "    \"50% discount promo!\",\n",
    "    \"The service was excellent and food delicious\",\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    pred = inference_pipeline(text)[0]\n",
    "    print(f\"Review: {text}\")\n",
    "    print(f\"Prediction: {label_names[int(pred['label'].split('_')[-1])]}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
